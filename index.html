<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
</head>
    <title>Ramana Sundararaman | Researcher in Computer Vision</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://cdn.jsdelivr.net/npm/aos@2.3.4/dist/aos.css" rel="stylesheet">
</head>
</head>
<body>
    <header>
        <h1>Ramana Sundararaman</h1>
        <!-- <p>Research Scientist • Builder • 3D Vision</p> -->
        <p class="tagline" data-aos="fade-up">I am a Researcher specializing in 3D computer vision, geometry processing and generative AI.</p>
        <div class="social-links">
            <a href="https://github.com/sentient07" target="_blank">
                <img src="github-icon.png" alt="GitHub" class="icon">
            </a>
            <a href="https://www.linkedin.com/in/ramanasundararaman/" target="_blank">
                <img src="linkedin-icon.png" alt="LinkedIn" class="icon">
            </a>
            <a href="https://ramonalouge.substack.com" target="_blank">
                <img src="blog-icon.png" alt="Blog" class="icon">
            </a>
            <a href="https://scholar.google.fr/citations?user=ZaSbYCsAAAAJ&hl=en" target="_blank">
                <img src="google-scholar-icon.png" alt="Google Scholar" class="icon">
            </a>
            <a href="mailto:vxrram.95@gmail.com">
                <img src="email-icon.png" alt="Email" class="icon">
            </a>
            <a href="Resume_Eng.pdf" target="_blank">
                <img src="resume.png" alt="Resume" class="icon">
            </a>
        </div>
    </header>
    <nav>
        <a href="#about">About</a>
        <a href="#selected-work">Research Publications</a>
        <a href="#projects">Projects</a>
        <a href="#open-source">Open Source</a>
        <a href="#education">Education</a>
        <a href="#service">Service</a>
        <a href="#talks">Talks</a>
        <a href="#teaching">Teaching</a>
    </nav>
    <main>
        <section id="about" data-aos="fade-up">
            <div class="about-content">
                <img src="your-photo.jpg" alt="Your Photo" data-aos="zoom-in">
                <div>
                    <h2>About</h2>
                    <p>
                        I recently completed my PhD at École Polytechnique, Paris, in the GeometriX group, advised by Maks Ovsjanikov. My work spans neural surface representations, 3D reconstruction, and shape correspondence. Prior to this, I earned a Master's in AI & Visual Computing from Ecole Polytechnique and an Electronics engineering degree from BITS Pilani, Goa.
                    </p>
                    <p>
                        <strong>Actively seeking research/engineering roles in domains where Vision and Graphics meet language.</strong>
                    </p>
                </div>
            </div>
        </section>
        <section id="selected-work">
            <h2>Research Publications</h2>
            <div class="research-list">
                <div class="paper" data-aos="fade-up">
                    <img src="thumbnail1.png" alt="Paper Thumbnail">
                    <div class="paper-details">
                        <p><strong>Deformation Recovery: Localized Learning for Detail-Preserving Deformations</strong></p>
                        <p class="authors">Authors: <strong>Ramana Sundararaman</strong>, Nicolas Donati, Simone Melzi, Etienne Corman, Maks Ovsjanikov</p>
                        <p> LJN is lightweight method for detail-preserving shape deformations using <em>local</em> Jacobians, where each triangle is considered as training example instead of the entire shape. LJN is thus data-friendly and can learn high-quality deformation (human) from as few as 60 pairs of shapes. </p>
                        <p class="conference">Presented at: <em> SIGGRAPH-Asia, Tokyo, 2024</em></p>
                        <div class="links">
                            <a href="https://github.com/sentient07/LJN">GitHub</a>
                            <a href="https://arxiv.org/pdf/2410.08225">Paper</a>
                            <!-- <a href="supplementary-link">Supplementary</a> -->
                        </div>
                    </div>
                </div>
                <div class="paper" data-aos="fade-up">
                    <img src="thumbnail0.png" alt="Paper Thumbnail">
                    <div class="paper-details">
                        <p><strong>Physical Property Estimation and Optimization via Constrained Latent Space Exploration</strong></p>
                        <p> A 3D Generative approach that estimates and improves physical properties while ensuring geometric plausibility by using latent space sampling within convex polytopes. Introduces a new dataset of annotated bottles. </p>
                        <p class="authors">Authors: <strong>Ramana Sundararaman</strong>, Jiqiong Qiu, Romain Savajano, Matthieu Pichaud, Maks Ovsjanikov</p>
                        <p class="conference"> Under-Review, 2024. </em></p>
                        <!-- <div class="links">
                            <a href="PhysicalLSO_.pdf" target="_blank"> Paper</a>
                        </div> -->
                    </div>
                </div>
                <div class="paper" data-aos="fade-up">
                    <img src="thumbnail2.png" alt="Paper Thumbnail">
                    <div class="paper-details">
                        <p><strong>Self-Supervised Dual Contouring</strong></p>
                        <p>SDC introduces self-supervised dual contouring for isosurface extraction, replacing supervised training with novel losses enforcing mesh-SDF consistency. It improves mesh extraction from SDFs that are produced by Deep Networks. </p>
                        <p class="authors">Authors: <strong>Ramana Sundararaman</strong>, Roman Klokov, Maks Ovsjanikov</p>
                        <p class="conference">Presented at: <em>CVPR (<strong>Spotlight</strong>), Seattle, 2024</em></p>
                        <div class="links">
                            <a href="https://github.com/Sentient07/SDC">GitHub</a>
                            <a href="https://www.lix.polytechnique.fr/~maks/papers/CVPR24_SDC.pdf">Paper</a>
                            <a href="https://www.lix.polytechnique.fr/~maks/papers/CVPR24_SDC_sup_mat.pdf">Supplementary</a>
                        </div>
                    </div>
                </div>
                <div class="paper" data-aos="fade-up">
                    <img src="thumbnail3.png" alt="Paper Thumbnail">
                    <div class="paper-details">
                        <p><strong>Reduced representation of deformation fields for effective non-rigid shape matching</strong></p>
                        <p> Marrying mesh-free approximation method with MLPs for non-rigid shape correspondence. Learning reduced deformation parameters to reconstruct smooth deformation, our approach enables efficient, limited supervision and achieves state-of-the-art results on shape matching benchmarks.</p>
                        <p class="authors">Authors: <strong>Ramana Sundararaman</strong>, Riccardo Marin, Emanuele Rodola, Maks Ovsjanikov</p>
                        <p class="conference">Presented at: <em>NeurIPS, New Orleans, 2022</em></p>
                        <div class="links">
                            <a href="https://github.com/Sentient07/DeformationBasis">GitHub</a>
                            <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/43d1d3bdd92204c96fa4ac3c578f6a33-Paper-Conference.pdf">Paper</a>
                            <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/43d1d3bdd92204c96fa4ac3c578f6a33-Supplemental-Conference.pdf">Supplementary</a>
                        </div>
                    </div>
                </div>
                <div class="paper" data-aos="fade-up">
                    <img src="thumbnail4.png" alt="Paper Thumbnail">
                    <div class="paper-details">
                        <p><strong>Implicit field supervision for robust non-rigid shape matching.</strong></p>
                        <p> An auto-decoder framework which learns continuous deformation fields for shape deformation, using Signed Distance Functions (SDFs) as regularization. Achieves strong performance on noisy, real-world data despite training on clean meshes.</p>
                        <p class="authors">Authors: <strong>Ramana Sundararaman</strong>, Gautam Pai, Maks Ovsjanikov</p>
                        <p class="conference">Presented at: <em> ECCV (<strong>Oral</strong>), Tel-Aviv, 2022</em></p>
                        <div class="links">
                            <a href="https://github.com/Sentient07/IFMatch">GitHub</a>
                            <a href="https://www.lix.polytechnique.fr/~maks/papers/ImplicitShapeCorr_ECCV2022.pdf">Paper</a>
                            <a href="https://www.lix.polytechnique.fr/~maks/papers/ImplicitShapeCorr_ECCV2022_sup.pdf">Supplementary</a>
                        </div>
                    </div>
                </div>
                <div class="paper" data-aos="fade-up">
                    <img src="thumbnail5.png" alt="Paper Thumbnail">
                    <div class="paper-details">
                        <p><strong>Tracking pedestrian heads in dense crowd.</strong></p>
                        <p> We introduce CroHD, a large annotated dataset for tracking in dense crowds, along with IDEucl metric to evaluate identity preservation. We also propose HeadHunter, a head detector combined with particle-filter-based tracking framework, which acheives superior results compared to state-of-the-art pedestrian trackers.</p>
                        <p class="authors">Authors: <strong>Ramana Sundararaman</strong>, Cedric Braga, Eric Marchand, Julien Pettre</p>
                        <p class="conference">Presented at: <em>CVPR, (Virtual), 2021</em></p>
                        <div class="links">
                            <a href="https://github.com/Sentient07/HeadHunter">GitHub</a>
                            <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Sundararaman_Tracking_Pedestrian_Heads_in_Dense_Crowd_CVPR_2021_paper.pdf">Paper</a>
                            <a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Sundararaman_Tracking_Pedestrian_Heads_CVPR_2021_supplemental.pdf">Supplementary</a>
                            <a href="https://motchallenge.net/data/Head_Tracking_21/">Dataset</a>
                        </div>
                    </div>
                </div>
                <div class="paper" data-aos="fade-up">
                    <img src="thumbnail6.png" alt="Paper Thumbnail">
                    <div class="paper-details">
                        <p><strong>Solving Inverse Computational Imaging Problems using Deep Pixel-level Prior.</strong></p>
                        <p> Uses autoregressive models as flexible signal priors for inverse imaging problems, enabling better reconstruction of images with texture. </p>
                        <p class="authors">Authors: Akshat Dave, Anil Vadathya, <strong>Ramana Sundararaman</strong>, Rahul Baburajan, Kaushik Mitra</p>
                        <p class="conference">Accepted at: <em>Transactions on Computational Imaging, 2018</em></p>
                        <div class="links">
                            <!-- <a href="https://github.com/Sentient07/HeadHunter">GitHub</a> -->
                            <a href="https://arxiv.org/abs/1802.09850">Paper</a>
                            <!-- <a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Sundararaman_Tracking_Pedestrian_Heads_CVPR_2021_supplemental.pdf">Supplementary</a> -->
                        </div>
                    </div>
                </div>


                <!-- Add more papers as needed -->
            </div>
        </section>
        <section id="projects" data-aos="fade-in">
            <h2>Projects</h2>
            <div class="paper" data-aos="fade-up" style="display: flex; align-items: center; gap: 1rem; margin-bottom: 2rem;">
                <div class="thumb" style="display:flex; flex-direction:column; align-items:center; width:300px;">
                    <img src="car_gif_2.gif" alt="3D car rotation" style="width: 300px; height: 300px; border-radius: 6px; background-color: #eee; object-fit: cover;">
                    <p class="coming-soon" style="color:#007BFF; font-style: italic; margin: 0.25rem 0 0 0;">(demo coming soon)</p>
                </div>
                <div class="paper-details">
                    <p><strong>Physically-Aware 3D Assets: Segment-driven Material Synthesis</strong></p>
                    <p>This project explores segment-level optimal physically-based rendering (PBR) materials to create realistic 3D assets. It focuses on enriching 3D geometry with accurate material semantics, enabling high-fidelity rendering of object parts. Segmentations are derived automatically, and material types are inferred using language-driven queries, enabling realistic and interpretable rendering of objects.</p>
                </div>
            </div>
            <div class="paper" data-aos="fade-up" style="display: flex; align-items: center; gap: 1rem; margin-bottom: 2rem;">
                <div class="thumb" style="display:flex; flex-direction:column; align-items:center; width:300px;">
                    <img src="llm_workflow2.png" alt="LLM workflow thumbnail" style="width: 300px; border-radius: 6px;">
                    <p class="coming-soon" style="color:#007BFF; font-style: italic; margin: 0.25rem 0 0 0;">(demo coming soon)</p>
                </div>
                <div class="paper-details">
                    <p><strong>LLM + RAG Email Generation with Adaptive Templates</strong></p>
                    <p>A template prompt (tone and structure rules) and a retrieved subset of client-based case files (RAG over a corpus) are fused in an LLM call to draft the email. The corpus is embedded and searched to select only relevant chunks before generation. Feedback text then updates the template automatically so later drafts improve without manual edits. An evaluation pass flags hallucinations and style issues and feeds a short report back into the loop. Outputs are the drafted email and the revised prompt.</p>
                </div>
            </div>
        </section>
        <section id="open-source" data-aos="fade-up">
        <section id="education" data-aos="fade-up">
            <h2>Education</h2>

            <div class="paper" style="display: flex; align-items: center; gap: 1rem; margin-bottom: 2rem;">
                <img src="2A03C404-0FCE-4A9A-A296-31C1DFA3A414.png" alt="PhD Thesis Thumbnail" style="width: 260px; border-radius: 6px;">
                <div class="paper-details">
                    <p><strong>PhD: Analysis of Large-Scale 3D Shape Collections with Learning-Based Approaches</strong></p>
                    <p>This thesis develops data-driven pipelines for shape deformation, correspondence, registration and optimization with limited supervision, supported by respective real-world applications.</p>
                    <p class="conference">École Polytechnique, 2025</p>
                    <div class="links">
                        <a href="https://theses.hal.science/tel-05129967" target="_blank">View Thesis</a>
                    </div>
                </div>
            </div>

            <div class="paper" style="display: flex; align-items: center; gap: 1rem;">
                <img src="thesis_logo.png" alt="Master's Thesis Thumbnail" style="width: 260px; border-radius: 6px;">
                <div class="paper-details">
                    <p><strong>Master’s: Implicit Latent Space Exploration for Shape Optimisation and Correspondence</strong></p>
                    <p class="conference">École Polytechnique, 2020</p>
                    <div class="links">
                        <a href="masters_thesis.pdf" target="_blank">Thesis (PDF)</a>
                    </div>
                </div>
            </div>
        </section>
            <h2>Open-Source Contributions</h2>
            <div class="open-source-entry">
                <p><strong>Theano (Google Summer of Code, 2016)</strong></p>
                <ul>
                    <li>Built a new “GraphToGPU” optimizer, enabling 2–3x faster compilation of deep nets like ResNet50.</li>
                    <li>Refactored computation graph using CGT-style grouping to reduce CPU-GPU memory transfers.</li>
                    <li>Implemented Spatial Pyramid and ROI Pooling layers with C++ and CUDA backends.</li>
                </ul>
            </div>
            <div class="open-source-entry">
                <p><strong>Protein Geometry Database (Google Summer of Code, 2015)</strong></p>
                <ul>
                    <li>Extended PostgreSQL schema and Django ORM logic to support occupancy and deposition filtering.</li>
                    <li>Redesigned user and search systems with Django auth and AngularJS, enabling tagged saved-searches.</li>
                </ul>
            </div>
        </section>
        <section id="service" data-aos="fade-up">
            <h2>Service</h2>
            <ul>
                <li>Reviewer: NeurIPS 2025, IEEE Transactions on Visualization and Computer Graphics (TVCG)</li>
            </ul>
        </section>

        <section id="talks" data-aos="fade-up">
            <h2>Talks</h2>
            <ul>
                <li>ECCV 2022, Tel-Aviv, Israel: Implicit field supervision for robust non-rigid shape matching.</li>
                <li>SIGGRAPH Asia 2024, Tokyo, Japan: Deformation Recovery: Localized Learning for Detail-Preserving Deformations.</li>
            </ul>
        </section>
        <section id="teaching">
            <h2>Teaching</h2>
            <ul>
                <li>
                    <strong>Computer Graphics</strong> - CSE-306, Ecole Polytechnique
                    <!-- <p>Brief description of the course.</p> -->
                </li>
                <li>
                    <strong>Geometric Deep Learning</strong> - INF-631, Ecole Polytechnique
                    <!-- <p>Brief description of the course.</p> -->
                </li>
                <li>
                    <strong>Computer Animation</strong> - INF-633, Ecole Polytechnique
                    <!-- <p>Brief description of the course.</p> -->
                </li>
                <li>
                    <strong>Introduction to Computer Science/Programming</strong> - INF-361, Ecole Polytechnique
                    <!-- <p>Brief description of the course.</p> -->
                </li>
                <!-- Add more courses as needed -->
            </ul>
        </section>
    </main>
    <footer>
        <p>&copy; 2024 Ramana Sundararaman. All rights reserved.</p>
    </footer>
</body>
<script src="https://cdn.jsdelivr.net/npm/aos@2.3.4/dist/aos.js"></script>
<script>
    AOS.init({
        once: true,
        duration: 800,
        easing: 'ease-in-out'
    });
</script>
</html>
